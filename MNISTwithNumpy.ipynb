{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTwithNumpy.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malyaban1/PyTorchDeepLearning/blob/master/MNISTwithNumpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vebvrUeIL68q",
        "colab_type": "code",
        "outputId": "74dbeb94-8da4-46d8-f7b2-3bca54abbc31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0714 20:53:58.261816 140675842025344 deprecation.py:323] From <ipython-input-1-31f1de9be2e5>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0714 20:53:58.263698 140675842025344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0714 20:53:58.264766 140675842025344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0714 20:53:58.528941 140675842025344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0714 20:53:58.533096 140675842025344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "W0714 20:53:58.589064 140675842025344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1JjUmYl3qg-f",
        "colab": {}
      },
      "source": [
        "def show_img(images, labels = []):\n",
        "  for index, image in enumerate(images):\n",
        "      if (labels.size != 0):\n",
        "        print('Label:', labels[index])\n",
        "      print('Digit in the image', np.argmax(labels[index]))\n",
        "      plt.imshow(image.reshape(28,28),cmap='gray')\n",
        "      plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myC5MRJgMOLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define hyper-parameters and necessary constants. We will use Relu as non-linearity\n",
        "\n",
        "batch_size = 32\n",
        "lr_rate = 0.001\n",
        "step = 0\n",
        "input_dim = 784\n",
        "output_dim = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHvHusQBN5en",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a model. It will have 3 layers.\n",
        "model = {}\n",
        "model['W1'] = np.random.randn(input_dim,16)\n",
        "model['W2'] = np.random.randn(16, 16)\n",
        "model['W3'] = np.random.randn(16, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elGlmiynRROc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def soft_max(x):\n",
        "  return (np.exp(x)/(np.sum(np.exp(x), axis=0)))\n",
        "\n",
        "def forward_pass(x):\n",
        "  h1 = np.dot(x,model['W1'])\n",
        "  h1[h1<=0] = 0\n",
        "  h2 = np.dot(h1,model['W2'])\n",
        "  h2[h2<=0] = 0\n",
        "  h3 = np.dot(h2,model['W3'])\n",
        "  h3[h3<=0] = 0\n",
        "  return x, h1, h2, h3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H1FLUFWay3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu_der(x):\n",
        "  x[x>0] = 1\n",
        "  x[x<=0] = 0\n",
        "  return x\n",
        "def back_prop(x, h1, h2, h3, e):\n",
        "  dW3 = np.dot(h2.T,2*e*relu_der(h3))\n",
        "  dW2 = np.dot(h1.T, np.dot(2*e*relu_der(h3),model['W3'].T)*relu_der(h2))\n",
        "  dW1 = np.dot(x.T, np.dot(np.dot(2*e*relu_der(h3),model['W3'].T)*relu_der(h2),model['W2'].T)*relu_der(h1))\n",
        "  model['W1'] += (lr_rate*dW1)\n",
        "  model['W2'] += (lr_rate*dW2)\n",
        "  model['W3'] += (lr_rate*dW3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6KoYftNnVzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train():\n",
        "  step = 0\n",
        "  for i in range(0,500000):\n",
        "    x,y = mnist.train.next_batch(batch_size)\n",
        "    x1, h1, h2, h3 = forward_pass(x)\n",
        "    y_pred = soft_max(h3.T).T\n",
        "    e = (y-y_pred)\n",
        "    back_prop(x1, h1, h2, h3, e)\n",
        "    step = step + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sP_TGDuoSmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test():\n",
        "  x,y = mnist.test.next_batch(10000)\n",
        "  show_\n",
        "  x, h1, h2, h3 = forward_pass(x)\n",
        "  success_count = 0\n",
        "  for i in range(0,10000):\n",
        "    if np.argmax(h3[i]) == np.argmax(y[i]):\n",
        "      success_count+=1\n",
        "  return success_count/10000.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAlwZ7ySrStt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTat30uq4174",
        "colab_type": "code",
        "outputId": "aae66f29-c9d3-4141-f245-b1e545e7c527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9414"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfcObAj4S_t0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}